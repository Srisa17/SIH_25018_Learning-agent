{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d64897d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03252359",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42f86f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_sym(symp):\n",
    "    # ===========================\n",
    "    # Step 1: Load Data\n",
    "    # ===========================\n",
    "    df = pd.read_csv(\"Disease_symptoms_new.csv\")  \n",
    "\n",
    "    X = df['Symptoms']\n",
    "    y = df['Disease']\n",
    "\n",
    "    # ===========================\n",
    "    # Step 2: Preprocess Text (Lemmatization)\n",
    "    # ===========================\n",
    "    def preprocess(text):\n",
    "        doc = nlp(str(text).lower())\n",
    "        # Keep only lemmas, remove stopwords & punctuation\n",
    "        return \" \".join([\n",
    "            token.lemma_ for token in doc \n",
    "            if not token.is_stop and token.is_alpha\n",
    "        ])\n",
    "\n",
    "    X = X.apply(preprocess)\n",
    "\n",
    "    # ===========================\n",
    "    # Step 3: Train/Test Split\n",
    "    # ===========================\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "    except ValueError:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "    # ===========================\n",
    "    # Step 4: Vectorize\n",
    "    # ===========================\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1,2),    # capture unigrams & bigrams\n",
    "        min_df=2              # ignore very rare terms\n",
    "    )\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # ===========================\n",
    "    # Step 5: Train Classifier\n",
    "    # ===========================\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # ===========================\n",
    "    # Step 6: Evaluate\n",
    "    # ===========================\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # ===========================\n",
    "    # Step 7: Prediction Function (Top-3 + Threshold)\n",
    "    # ===========================\n",
    "    def predict_top3(symptoms_list, threshold=0.7):\n",
    "        cleaned = [preprocess(text) for text in symptoms_list]\n",
    "        features = vectorizer.transform(cleaned)\n",
    "        proba = model.predict_proba(features)\n",
    "        classes = model.classes_\n",
    "        \n",
    "        results = []\n",
    "        for raw_sym, clean_sym, probs in zip(symptoms_list, cleaned, proba):\n",
    "            # sort probs in descending order\n",
    "            top_idx = np.argsort(probs)[::-1][:3]\n",
    "            top_diseases = [(classes[i], float(probs[i])) for i in top_idx]\n",
    "\n",
    "            # main prediction with threshold\n",
    "            pred = classes[top_idx[0]] if probs[top_idx[0]] >= threshold else \"Uncertain\"\n",
    "            \n",
    "            results.append({\n",
    "                \"Original Input\": raw_sym,\n",
    "                \"Preprocessed\": clean_sym,\n",
    "                \"Prediction\": pred,\n",
    "                \"Top 3\": top_diseases\n",
    "            })\n",
    "\n",
    "        confidence_df = pd.DataFrame(proba, columns=classes, index=symptoms_list)\n",
    "        return results, confidence_df\n",
    "\n",
    "\n",
    "    preds, confidence_matrix = predict_top3(symp)\n",
    "\n",
    "    for res in preds:\n",
    "        print(f\"\\nOriginal: {res['Original Input']}\")\n",
    "        print(f\"Preprocessed: {res['Preprocessed']}\")\n",
    "        if res['Prediction']!='Uncertain':\n",
    "            print(f\"Predicted Disease: {res['Prediction']}\")\n",
    "        print(\"Top 3 likely diseases:\")\n",
    "        for disease, score in res['Top 3']:\n",
    "            print(f\"{disease}: {score:.2f}\")\n",
    "\n",
    "    print(type(preds))\n",
    "    return preds\n",
    "    # print(\"\\nConfidence Matrix:\\n\")\n",
    "    # print(confidence_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "350b84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_test(lst_dis):\n",
    "    df_test = pd.read_csv('Disease_Tests.csv')\n",
    "    display(df_test.head(10))  # optional\n",
    "\n",
    "    for entry in lst_dis:\n",
    "        original_input = entry['Original Input']\n",
    "        top3 = entry['Top 3']\n",
    "\n",
    "        print(f\"\\nSymptom Input: '{original_input}'\")\n",
    "        \n",
    "        for disease, score in top3:\n",
    "            test_row = df_test.loc[df_test['Disease'] == disease]\n",
    "            if not test_row.empty:\n",
    "                tests = \", \".join(test_row['Tests'].values)\n",
    "                print(f\"Disease: {disease}, Suggested Tests: {tests}\")\n",
    "            else:\n",
    "                print(f\"Disease: {disease}, No tests found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b71e2764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_int(lst_int):\n",
    "    # Load intensity dataset\n",
    "    df_test = pd.read_csv('Disease_Intensity.csv')\n",
    "    display(df_test.head(10))\n",
    "\n",
    "    for entry in lst_int:\n",
    "        original_input = entry['Symptoms'] if 'Symptoms' in entry else entry['Original Input']\n",
    "        top3 = entry['Top 3']\n",
    "\n",
    "        print(f\"\\nSymptom Input: '{original_input}'\")\n",
    "        \n",
    "        for disease, score in top3:\n",
    "            test_row = df_test.loc[df_test['Disease'] == disease]\n",
    "            if not test_row.empty:\n",
    "                intensity = \", \".join(test_row['Intensity'].values)\n",
    "                if intensity == 'Emergency':\n",
    "                    print(f\"Disease: {disease}, Intensity: {intensity} ðŸš¨ Trigger Emergency ðŸš¨\")\n",
    "                else:\n",
    "                    print(f\"Disease: {disease}, Intensity: {intensity}\")\n",
    "            else:\n",
    "                print(f\"Disease: {disease}, No intensity info found\")\n",
    "\n",
    "sym = [\"cough, nausea\"]\n",
    "p = dis_sym(sym) \n",
    "dis_int(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4401c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
