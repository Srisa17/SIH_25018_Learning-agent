{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa5fca20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\klvns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\klvns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "c:\\Users\\klvns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:992: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "C:\\Users\\klvns\\AppData\\Local\\Temp\\ipykernel_19840\\868439179.py:21: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import EncoderClassifier\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Cell 1: Imports & Setup\n",
    "# ==========================\n",
    "import os\n",
    "import io\n",
    "import joblib\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wavfile\n",
    "import spacy\n",
    "from googletrans import Translator\n",
    "import speech_recognition as sr\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# optional / heavy deps (wrapped later)\n",
    "try:\n",
    "    from speechbrain.pretrained import EncoderClassifier\n",
    "    SPEECHBRAIN_AVAILABLE = True\n",
    "except Exception:\n",
    "    SPEECHBRAIN_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import torchaudio\n",
    "except Exception:\n",
    "    torchaudio = None\n",
    "\n",
    "# Fallback sentiment + acoustic features\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "except Exception:\n",
    "    TRANSFORMERS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import librosa\n",
    "except Exception:\n",
    "    librosa = None\n",
    "\n",
    "# Language model for text preprocessing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# File names (non-hardcoded dataset names used, user can change)\n",
    "SYMPTOM_FILE = \"Disease_symptoms_new.csv\"    # should have columns: Disease,Symptoms  (order tolerant)\n",
    "TEST_FILE = \"Disease_Tests.csv\"              # should have column 'Disease' and other test columns\n",
    "INTENSITY_FILE = \"Disease_Intensity.csv\"     # should have columns ['Disease','Intensity'] or similar\n",
    "\n",
    "MODEL_FILE = \"disease_model.pkl\"\n",
    "VECTORIZER_FILE = \"vectorizer.pkl\"\n",
    "\n",
    "# A small keywords list to help with symptom extraction if needed\n",
    "DEFAULT_SYMPTOMS = [\n",
    "    \"fever\",\"cough\",\"headache\",\"fatigue\",\"nausea\",\"vomiting\",\"dizziness\",\"chest pain\",\n",
    "    \"shortness of breath\",\"sore throat\",\"diarrhea\",\"rash\",\"body ache\",\"cold\",\"congestion\",\n",
    "    \"chills\",\"loss of taste\",\"loss of smell\",\"runny nose\",\"muscle pain\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d698182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Cell: Translation Utils\n",
    "# ==========================\n",
    "from langdetect import detect\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "def ensure_english(text: str) -> str:\n",
    "    \"\"\"Detects language and translates to English if needed.\"\"\"\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except Exception:\n",
    "        lang = \"unknown\"\n",
    "    if lang != \"en\":\n",
    "        try:\n",
    "            translated = translator.translate(text, src=lang, dest=\"en\").text\n",
    "            print(f\"ðŸŒ Translated from {lang} â†’ en: {translated}\")\n",
    "            return translated\n",
    "        except Exception as e:\n",
    "            print(\"âš ï¸ Translation failed, using original text:\", e)\n",
    "            return text\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb851832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Cell 2: Preprocess & Utilities\n",
    "# ==========================\n",
    "def preprocess(text):\n",
    "    \"\"\"Light lemmatization + stopword/punct removal using spaCy.\"\"\"\n",
    "    doc = nlp(str(text).lower())\n",
    "    return \" \".join([token.lemma_ for token in doc if token.is_alpha and not token.is_stop])\n",
    "\n",
    "def ensure_dataframe_columns(df, expected_cols):\n",
    "    \"\"\"Return dataframe with expected columns (case-insensitive).\"\"\"\n",
    "    cols_lower = {c.lower(): c for c in df.columns}\n",
    "    mapping = {}\n",
    "    for col in expected_cols:\n",
    "        if col.lower() in cols_lower:\n",
    "            mapping[cols_lower[col.lower()]] = col\n",
    "    if mapping:\n",
    "        df = df.rename(columns=mapping)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01ea64bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Cell 3: SymptomAgent Class (learning agent)\n",
    "# ==========================\n",
    "class SymptomAgent:\n",
    "    def __init__(self, symptom_file=SYMPTOM_FILE, test_file=TEST_FILE, intensity_file=INTENSITY_FILE):\n",
    "        self.symptom_file = symptom_file\n",
    "        self.test_file = test_file\n",
    "        self.intensity_file = intensity_file\n",
    "\n",
    "        # load datasets (will raise if not present)\n",
    "        self.df_symptoms = pd.read_csv(self.symptom_file)\n",
    "        self.df_symptoms = ensure_dataframe_columns(self.df_symptoms, [\"Disease\", \"Symptoms\"])\n",
    "        # ensure columns exist\n",
    "        if \"Disease\" not in self.df_symptoms.columns or \"Symptoms\" not in self.df_symptoms.columns:\n",
    "            raise ValueError(f\"{self.symptom_file} must contain columns 'Disease' and 'Symptoms'\")\n",
    "\n",
    "        if os.path.exists(self.test_file):\n",
    "            self.df_tests = pd.read_csv(self.test_file)\n",
    "            self.df_tests = ensure_dataframe_columns(self.df_tests, [\"Disease\"])\n",
    "        else:\n",
    "            self.df_tests = pd.DataFrame(columns=[\"Disease\"])\n",
    "\n",
    "        if os.path.exists(self.intensity_file):\n",
    "            self.df_intensity = pd.read_csv(self.intensity_file)\n",
    "            self.df_intensity = ensure_dataframe_columns(self.df_intensity, [\"Disease\",\"Intensity\"])\n",
    "        else:\n",
    "            self.df_intensity = pd.DataFrame(columns=[\"Disease\",\"Intensity\"])\n",
    "\n",
    "        # Load or train model\n",
    "        self.vectorizer = None\n",
    "        self.model = None\n",
    "        self._load_or_train()\n",
    "\n",
    "    def _load_or_train(self):\n",
    "        \"\"\"Load saved model+vectorizer if present; otherwise train from CSV.\"\"\"\n",
    "        if os.path.exists(MODEL_FILE) and os.path.exists(VECTORIZER_FILE):\n",
    "            try:\n",
    "                self.model = joblib.load(MODEL_FILE)\n",
    "                self.vectorizer = joblib.load(VECTORIZER_FILE)\n",
    "                return\n",
    "            except Exception:\n",
    "                # fallback to retrain\n",
    "                print(\"Warning: failed loading model files; retraining from CSV.\")\n",
    "        self._train_from_csv()\n",
    "\n",
    "    def _train_from_csv(self):\n",
    "        \"\"\"Train TF-IDF + Logistic Regression on current CSV.\"\"\"\n",
    "        df = self.df_symptoms.copy()\n",
    "        # Preprocess text column (do not overwrite original CSV)\n",
    "        df['__proc__'] = df['Symptoms'].apply(preprocess)\n",
    "        X = df['__proc__'].astype(str)\n",
    "        y = df['Disease'].astype(str)\n",
    "\n",
    "        # vectorizer min_df=1 to avoid dropping rare symptom combos\n",
    "        self.vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "        X_tfidf = self.vectorizer.fit_transform(X)\n",
    "\n",
    "        self.model = LogisticRegression(max_iter=2000)\n",
    "        self.model.fit(X_tfidf, y)\n",
    "\n",
    "        # save for reuse\n",
    "        joblib.dump(self.model, MODEL_FILE)\n",
    "        joblib.dump(self.vectorizer, VECTORIZER_FILE)\n",
    "\n",
    "    def predict_top3(self, inputs, threshold=0.7):\n",
    "        \"\"\"inputs: list of raw symptom strings. returns list of dicts per input.\"\"\"\n",
    "        processed = [preprocess(s) for s in inputs]\n",
    "        X_tfidf = self.vectorizer.transform(processed)\n",
    "        proba = self.model.predict_proba(X_tfidf)\n",
    "        classes = self.model.classes_\n",
    "\n",
    "        results = []\n",
    "        for raw, proc, probs in zip(inputs, processed, proba):\n",
    "            top_idx = np.argsort(probs)[::-1][:3]\n",
    "            top3 = [(classes[i], float(probs[i])) for i in top_idx]\n",
    "            pred = classes[top_idx[0]] if probs[top_idx[0]] >= threshold else \"Uncertain\"\n",
    "            results.append({\n",
    "                \"Original Input\": raw,\n",
    "                \"Preprocessed\": proc,\n",
    "                \"Prediction\": pred,\n",
    "                \"Top 3\": top3\n",
    "            })\n",
    "        return results\n",
    "\n",
    "    def suggest_tests(self, predictions):\n",
    "        \"\"\"predictions: list of dicts returned by predict_top3\"\"\"\n",
    "        out = []\n",
    "        for entry in predictions:\n",
    "            original = entry['Original Input']\n",
    "            tests_info = []\n",
    "            for disease, score in entry['Top 3']:\n",
    "                row = self.df_tests.loc[self.df_tests['Disease'] == disease]\n",
    "                if not row.empty:\n",
    "                    test_columns = [c for c in row.columns if c != 'Disease']\n",
    "                    # join non-null values\n",
    "                    vals = [str(v) for v in row.iloc[0][test_columns].values if pd.notna(v) and str(v).strip() != \"\"]\n",
    "                    tests = \", \".join(vals) if vals else \"No tests listed\"\n",
    "                else:\n",
    "                    tests = \"No tests found\"\n",
    "                tests_info.append((disease, score, tests))\n",
    "            out.append({\"input\": original, \"tests\": tests_info})\n",
    "        return out\n",
    "\n",
    "    def check_intensity(self, predictions):\n",
    "        \"\"\"Return intensity info (Emergency etc.) for each disease in top3.\"\"\"\n",
    "        out = []\n",
    "        for entry in predictions:\n",
    "            info = []\n",
    "            for disease, score in entry['Top 3']:\n",
    "                row = self.df_intensity.loc[self.df_intensity['Disease'] == disease]\n",
    "                if not row.empty and 'Intensity' in row.columns:\n",
    "                    intensity_vals = [str(v) for v in row['Intensity'].values if pd.notna(v)]\n",
    "                    intensity = \", \".join(intensity_vals)\n",
    "                else:\n",
    "                    intensity = \"Unknown\"\n",
    "                info.append((disease, score, intensity))\n",
    "            out.append({\"input\": entry['Original Input'], \"intensity\": info})\n",
    "        return out\n",
    "\n",
    "    def update_with_feedback(self, symptom_text, confirmed_disease):\n",
    "        \"\"\"Append confirmed pair to CSV and retrain the model.\"\"\"\n",
    "        # Append to dataframe in memory\n",
    "        new_row = {\"Disease\": confirmed_disease, \"Symptoms\": symptom_text}\n",
    "        self.df_symptoms = pd.concat([self.df_symptoms, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "        # Append to CSV (preserve column order if possible)\n",
    "        # If CSV has header Disease,Symptoms we preserve that\n",
    "        try:\n",
    "            self.df_symptoms.to_csv(self.symptom_file, index=False)\n",
    "        except Exception as e:\n",
    "            print(\"Warning: couldn't write to CSV:\", e)\n",
    "\n",
    "        # retrain model (overwrite saved files)\n",
    "        if os.path.exists(MODEL_FILE): os.remove(MODEL_FILE)\n",
    "        if os.path.exists(VECTORIZER_FILE): os.remove(VECTORIZER_FILE)\n",
    "        self._train_from_csv()\n",
    "        print(f\"âœ… Learned: '{symptom_text}' -> {confirmed_disease}\")\n",
    "\n",
    "    # utility: return raw dataframes head for inspection\n",
    "    def show_data_preview(self, n=5):\n",
    "        return {\n",
    "            \"symptoms_head\": self.df_symptoms.tail(n),\n",
    "            \"tests_head\": self.df_tests.head(n),\n",
    "            \"intensity_head\": self.df_intensity.head(n)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a3a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\klvns\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.\n",
      "  warnings.warn(\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpeechBrain available but failed to load model; falling back. [WinError 1314] A required privilege is not held by the client: 'C:\\\\Users\\\\klvns\\\\.cache\\\\huggingface\\\\hub\\\\models--speechbrain--emotion-recognition-wav2vec2-IEMOCAP\\\\snapshots\\\\117a9c3dff08be81a3628eecf6a66b547ec1659b\\\\hyperparams.yaml' -> 'd:\\\\srisa_c\\\\SIH_2025\\\\pretrained_models\\\\emotion_recog\\\\hyperparams.yaml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Cell 4: Emotion & Urgency Detection (SpeechBrain + fallback)\n",
    "# ==========================\n",
    "# Try speechbrain model if available -- otherwise fallback to text+acoustic heuristics\n",
    "SB_CLASSIFIER = None\n",
    "if SPEECHBRAIN_AVAILABLE:\n",
    "    try:\n",
    "        SB_CLASSIFIER = EncoderClassifier.from_hparams(\n",
    "            source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\",\n",
    "            savedir=\"pretrained_models/emotion_recog\"\n",
    "        )\n",
    "        print(\"SpeechBrain encoder classifier loaded.\")\n",
    "    except Exception as e:\n",
    "        print(\"SpeechBrain available but failed to load model; falling back.\", e)\n",
    "        SB_CLASSIFIER = None\n",
    "\n",
    "# transformers sentiment pipeline (optional fallback)\n",
    "SENTIMENT_PIPE = None\n",
    "if TRANSFORMERS_AVAILABLE:\n",
    "    try:\n",
    "        SENTIMENT_PIPE = pipeline(\"sentiment-analysis\")\n",
    "    except Exception:\n",
    "        SENTIMENT_PIPE = None\n",
    "\n",
    "def acoustic_heuristics(wav_path, sr_target=16000):\n",
    "    \"\"\"Compute simple acoustic stats. Returns dict and urgent boolean.\"\"\"\n",
    "    if librosa is None:\n",
    "        return {\"rms\": None, \"zcr\": None, \"pitch_var\": None, \"urgent\": False}\n",
    "    y, sr = librosa.load(wav_path, sr=sr_target)\n",
    "    rms = float(np.mean(librosa.feature.rms(y=y)))\n",
    "    zcr = float(np.mean(librosa.feature.zero_crossing_rate(y)))\n",
    "    # pitch variance may be noisy; handle exceptions\n",
    "    try:\n",
    "        f0, voiced_flag, voiced_probs = librosa.pyin(\n",
    "            y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), sr=sr\n",
    "        )\n",
    "        pitch_var = float(np.nanvar(f0))\n",
    "    except Exception:\n",
    "        pitch_var = 0.0\n",
    "    # heuristic thresholds (tune if needed)\n",
    "    urgent = (rms is not None and rms > 0.02 and pitch_var > 200) or (zcr > 0.25 if zcr is not None else False)\n",
    "    return {\"rms\": rms, \"zcr\": zcr, \"pitch_var\": pitch_var, \"urgent\": bool(urgent)}\n",
    "\n",
    "def detect_emotion_and_urgency(wav_path, transcript=None):\n",
    "    \"\"\"\n",
    "    Returns dict:\n",
    "    {\n",
    "      'source': 'speechbrain'|'fallback',\n",
    "      'label': str or None,\n",
    "      'score': float or None,\n",
    "      'acoustic': {...},\n",
    "      'urgent': bool\n",
    "    }\n",
    "    \"\"\"\n",
    "    result = {\"source\": None, \"label\": None, \"score\": None, \"acoustic\": None, \"urgent\": False}\n",
    "\n",
    "    # 1) SpeechBrain if available\n",
    "    if SB_CLASSIFIER is not None:\n",
    "        try:\n",
    "            # speechbrain classify_file returns lists; wrapper used here\n",
    "            out_prob, score, index, text_lab = SB_CLASSIFIER.classify_file(wav_path)\n",
    "            label = text_lab[0] if isinstance(text_lab, (list, tuple)) else text_lab\n",
    "            result.update({\"source\": \"speechbrain\", \"label\": str(label), \"score\": float(score)})\n",
    "            result[\"acoustic\"] = acoustic_heuristics(wav_path)\n",
    "            # emergency set:\n",
    "            emergency_set = {\"angry\", \"fearful\", \"surprised\", \"panic\", \"frightened\"}\n",
    "            result[\"urgent\"] = (str(label).lower() in emergency_set) or result[\"acoustic\"][\"urgent\"]\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(\"SpeechBrain inference error, falling back:\", e)\n",
    "\n",
    "    # 2) Fallback: use STT â†’ text sentiment (if available) + acoustic heuristics\n",
    "    result[\"source\"] = \"fallback\"\n",
    "    if transcript is None:\n",
    "        # try speech_recognition to get transcript\n",
    "        try:\n",
    "            r = sr.Recognizer()\n",
    "            with sr.AudioFile(wav_path) as src:\n",
    "                aud = r.record(src)\n",
    "            transcript = r.recognize_google(aud, language=\"en-IN\")\n",
    "        except Exception:\n",
    "            transcript = None\n",
    "\n",
    "    if transcript and SENTIMENT_PIPE is not None:\n",
    "        try:\n",
    "            out = SENTIMENT_PIPE(transcript)[0]\n",
    "            lab = \"distressed\" if out['label'].upper().startswith(\"NEG\") else \"calm\"\n",
    "            result[\"label\"] = lab\n",
    "            result[\"score\"] = float(out['score'])\n",
    "        except Exception:\n",
    "            result[\"label\"] = None\n",
    "            result[\"score\"] = None\n",
    "    else:\n",
    "        result[\"label\"] = None\n",
    "        result[\"score\"] = None\n",
    "\n",
    "    result[\"acoustic\"] = acoustic_heuristics(wav_path)\n",
    "    result[\"urgent\"] = result[\"acoustic\"][\"urgent\"] or (result[\"label\"] == \"distressed\" and (result[\"score\"] or 0) > 0.8)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520890d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Cell 5: Audio capture + helpers\n",
    "# ==========================\n",
    "def record_to_file(filename=\"temp.wav\", duration=8, sample_rate=16000):\n",
    "    \"\"\"Record from default mic using sounddevice and save to WAV file.\"\"\"\n",
    "    print(f\"\\n Recording for {duration} seconds... speak now.\")\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='float32')\n",
    "    sd.wait()\n",
    "    data = np.squeeze(recording)\n",
    "    # convert to int16 PCM\n",
    "    int_data = np.int16(data * 32767)\n",
    "    wavfile.write(filename, sample_rate, int_data)\n",
    "    print(f\"Saved recording to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def stt_from_file(filename, language=\"en-IN\"):\n",
    "    \"\"\"Speech-to-text using speech_recognition + Google (requires internet).\"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    try:\n",
    "        with sr.AudioFile(filename) as src:\n",
    "            audio = r.record(src)\n",
    "        text = r.recognize_google(audio, language=language)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"STT: Speech not understood.\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"STT: Request error:\", e)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "840b671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Cell 6: Integration / Main interactive loop\n",
    "# ==========================\n",
    "def run_voice_interaction(agent: SymptomAgent,\n",
    "                          record_duration=6,\n",
    "                          sample_rate=16000,\n",
    "                          stt_language=\"en-IN\"):\n",
    "    \"\"\"\n",
    "    Records audio, transcribes, translates to English, gets top-3 disease predictions, \n",
    "    suggests tests, checks intensity + emotion urgency, then offers feedback learning.\n",
    "    \"\"\"\n",
    "    # 1) Record\n",
    "    wav_path = record_to_file(\"temp.wav\", duration=record_duration, sample_rate=sample_rate)\n",
    "\n",
    "        # 2) Speech-to-text (transcript) + auto-detect Indian language\n",
    "    transcript_raw = stt_from_file(wav_path, language=\"hi-IN\")  # default Hindi for STT\n",
    "    if transcript_raw:\n",
    "        print(f\"\\nðŸ—£ï¸ Transcribed text: {transcript_raw}\")\n",
    "    else:\n",
    "        print(\"\\nðŸ—£ï¸ STT failed; will attempt fallback transcription.\")\n",
    "        transcript_raw = \"\"\n",
    "\n",
    "    # 3) Translate to English from any Indian language\n",
    "    # We use src='auto' to detect source language automatically\n",
    "    try:\n",
    "        translated = translator.translate(transcript_raw, src='auto', dest='en').text\n",
    "        print(f\"ðŸŒ Detected language â†’ Translated to English: {translated}\")\n",
    "        transcript_en = translated\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Translation failed; using original text:\", e)\n",
    "        transcript_en = transcript_raw\n",
    "\n",
    "\n",
    "    # 4) Predict disease(s)\n",
    "    predictions = agent.predict_top3([transcript_en])\n",
    "    for p in predictions:\n",
    "        print(\"\\n--- Prediction ---\")\n",
    "        print(\"Original Input:\", p[\"Original Input\"])\n",
    "        print(\"Preprocessed:\", p[\"Preprocessed\"])\n",
    "        print(\"Top 3:\")\n",
    "        for d, s in p[\"Top 3\"]:\n",
    "            print(f\"  {d} ({s:.3f})\")\n",
    "        print(\"Main prediction:\", p[\"Prediction\"])\n",
    "\n",
    "    # 5) Suggest tests & intensity\n",
    "    tests = agent.suggest_tests(predictions)\n",
    "    for t in tests:\n",
    "        print(\"\\n--- Suggested Tests ---\")\n",
    "        print(f\"For input: {t['input']}\")\n",
    "        for disease, score, teststr in t['tests']:\n",
    "            print(f\"  {disease} ({score:.3f}) -> Tests: {teststr}\")\n",
    "\n",
    "    intens = agent.check_intensity(predictions)\n",
    "    for it in intens:\n",
    "        print(\"\\n--- Intensity Info ---\")\n",
    "        print(f\"For input: {it['input']}\")\n",
    "        for disease, score, intensity in it['intensity']:\n",
    "            note = \" ðŸš¨ EMERGENCY\" if str(intensity).lower().strip() == \"emergency\" else \"\"\n",
    "            print(f\"  {disease} ({score:.3f}) -> Intensity: {intensity}{note}\")\n",
    "\n",
    "    # 6) Emotion + urgency detection\n",
    "    emo = detect_emotion_and_urgency(wav_path, transcript=transcript_en)\n",
    "    print(\"\\n--- Emotion / Urgency ---\")\n",
    "    print(f\"Source: {emo['source']}\")\n",
    "    print(f\"Label: {emo['label']}, Score: {emo['score']}\")\n",
    "    print(\"Acoustic features:\", emo['acoustic'])\n",
    "    print(\"Urgent:\", emo['urgent'])\n",
    "\n",
    "    # 7) Emergency escalation check\n",
    "    emergency_by_intensity = any(str(x[2]).lower().strip() == \"emergency\" for x in intens[0][\"intensity\"])\n",
    "    if emo['urgent'] or emergency_by_intensity:\n",
    "        print(\"\\nâš ï¸ EMERGENCY DETECTED â€” prioritize immediately! âš ï¸\")\n",
    "        # optional: send alert via SMS/email/UI\n",
    "\n",
    "    # 8) Feedback loop\n",
    "    for p in predictions:\n",
    "        user_confirm = input(f\"\\nWas the top prediction '{p['Prediction']}' correct? (yes/no/skip): \").strip().lower()\n",
    "        if user_confirm == \"yes\":\n",
    "            agent.update_with_feedback(p[\"Original Input\"], p[\"Prediction\"])\n",
    "        elif user_confirm == \"no\":\n",
    "            correct = input(\"Enter the correct disease name (exact): \").strip()\n",
    "            if correct:\n",
    "                agent.update_with_feedback(p[\"Original Input\"], correct)\n",
    "        else:\n",
    "            print(\"Skipping feedback for this example.\")\n",
    "\n",
    "    print(\"\\nâœ… Interaction completed. Model persisted to disk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c66085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent ready. Data preview (tail):\n",
      "        Disease           Symptoms\n",
      "1248  Uncertain  Jwalamuchi telugu\n",
      "1249  Uncertain       cold and flu\n",
      "1250  Uncertain    Winter and cold\n",
      "\n",
      " Recording for 6 seconds... speak now.\n",
      "Saved recording to: temp.wav\n",
      "\n",
      "ðŸ—£ï¸ Transcribed text: à¤†à¤ˆ à¤¹à¥ˆà¤µ à¤ à¤«à¥‡à¤µà¤° à¤à¤‚à¤¡ à¤•à¥‹à¤²à¥à¤¡\n",
      "ðŸŒ Detected language â†’ Translated to English: I have a favorite and cold\n",
      "\n",
      "--- Prediction ---\n",
      "Original Input: I have a favorite and cold\n",
      "Preprocessed: favorite cold\n",
      "Top 3:\n",
      "  Hypothyroidism (0.014)\n",
      "  Uncertain (0.012)\n",
      "  Cystic Fibrosis (0.006)\n",
      "Main prediction: Uncertain\n",
      "\n",
      "--- Suggested Tests ---\n",
      "For input: I have a favorite and cold\n",
      "  Hypothyroidism (0.014) -> Tests: No tests found\n",
      "  Uncertain (0.012) -> Tests: No tests found\n",
      "  Cystic Fibrosis (0.006) -> Tests: No tests found\n",
      "\n",
      "--- Intensity Info ---\n",
      "For input: I have a favorite and cold\n",
      "  Hypothyroidism (0.014) -> Intensity: Unknown\n",
      "  Uncertain (0.012) -> Intensity: Unknown\n",
      "  Cystic Fibrosis (0.006) -> Intensity: Unknown\n",
      "\n",
      "--- Emotion / Urgency ---\n",
      "Source: fallback\n",
      "Label: distressed, Score: 0.9889146685600281\n",
      "Acoustic features: {'rms': 0.03875387832522392, 'zcr': 0.09727445561835106, 'pitch_var': 1487.0933675406575, 'urgent': True}\n",
      "Urgent: True\n",
      "\n",
      "âš ï¸ EMERGENCY DETECTED â€” prioritize immediately! âš ï¸\n",
      "âœ… Learned: 'I have a favorite and cold' -> malaria\n",
      "\n",
      "âœ… Interaction completed. Model persisted to disk.\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Cell 7: Run example\n",
    "# ==========================\n",
    "if __name__ == \"__main__\":\n",
    "    # initialize agent\n",
    "    agent = SymptomAgent(symptom_file=SYMPTOM_FILE, test_file=TEST_FILE, intensity_file=INTENSITY_FILE)\n",
    "    print(\"Agent ready. Data preview (tail):\")\n",
    "    preview = agent.show_data_preview(n=3)\n",
    "    print(preview[\"symptoms_head\"])\n",
    "    # Run interactive voice session (will record from mic)\n",
    "    run_voice_interaction(agent, record_duration=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93213a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
